question,answer,contexts,ground_truths
What are the advantages of retrieval-augmented text generation compared to conventional generation models?,"Retrieval-augmented text generation has several advantages compared to conventional generation models:

1. Scalability: Retrieval-augmented text generation allows for explicit acquisition of knowledge in a plug-and-play manner, rather than implicitly storing it in model parameters. This leads to greater scalability as the model can easily incorporate new knowledge sources.

2. Improved Performance: Retrieval-augmented text generation has achieved state-of-the-art performance in many natural language processing (NLP) tasks. By generating text from retrieved human-written references, it leverages existing high-quality content, potentially alleviating the difficulty of text generation.

3. Access to Diverse Information: By retrieving information from various sources, retrieval-augmented text generation can access a wide range of diverse information. This can enhance the coverage of useful information and improve the quality of generated text.

Overall, retrieval-augmented text generation combines the strengths of deep learning technology and traditional retrieval technology, offering advantages in scalability, performance, and access to diverse information.","['A Survey on Retrieval-Augmented Text Generation\nHuayang Li♥,∗\nYixuan Su♠,∗\nDeng Cai♦,∗\nYan Wang♣,∗\nLemao Liu♣,∗\n♥Nara Institute of Science and Technology\n♠University of Cambridge\n♦The Chinese University of Hong Kong\n♣Tencent AI Lab\nli.huayang.lh6@is.naist.jp, ys484@cam.ac.uk\nthisisjcykcd@gmail.com, brandenwang@tencent.com\nlemaoliu@gmail.com\nAbstract\nRecently, retrieval-augmented text generation\nattracted increasing attention of the compu-\ntational linguistics community.\nCompared\nwith conventional generation models, retrieval-\naugmented text generation has remarkable ad-\nvantages and particularly has achieved state-of-\nthe-art performance in many NLP tasks. This\npaper aims to conduct a survey about retrieval-\naugmented text generation. It ﬁrstly highlights\nthe generic paradigm of retrieval-augmented\ngeneration, and then it reviews notable ap-\nproaches according to different tasks including\ndialogue response generation, machine trans-\nlation, and other generation tasks. Finally, it'
 'more helpful in machine translation, and so on. On\nthe other hand, using a universal metric for retrieval\nmay lead to the lack of diversity of the retrieval re-\nsults. Collecting a diverse set of retrieval results\ncan improve the coverage of useful information.\nThus, considering multiple different metrics for re-\ntrieval may lead to generation with higher quality\nin the future.\n7\nConclusion\nIn this paper, we surveyed recent approaches for\nretrieval-augmented text generation. We reviewed\nand summarized the development of different com-\nponents of retrieval-augmented text generation in-\ncluding retrieval metrics, retrieval sources, and in-\ntegration paradigms. We gave in-depth discussions\nwhen retrieval-augmented text generation comes to\ndifferent applications including dialogue response\ngeneration, machine translation, and other genera-\ntion tasks. We also pointed out some future direc-\ntions for retrieval-augmented text generation.\nReferences'
 'dialogue response generation, machine trans-\nlation, and other generation tasks. Finally, it\npoints out some promising directions on top of\nrecent methods to facilitate future research.\n1\nIntroduction\nRetrieval-augmented text generation, as a new\ntext generation paradigm that fuses emerging deep\nlearning technology and traditional retrieval tech-\nnology, has achieved state-of-the-art (SOTA) per-\nformance in many NLP tasks and attracted the at-\ntention of the computational linguistics community\n(Weston et al., 2018; Dinan et al., 2018; Cai et al.,\n2021). Compared with generation-based counter-\npart, this new paradigm has some remarkable ad-\nvantages: 1) The knowledge is not necessary to be\nimplicitly stored in model parameters, but is explic-\nitly acquired in a plug-and-play manner, leading\nto great scalibility; 2) Instead of generating from\nscratch, the paradigm generating text from some re-\ntrieved human-written reference, which potentially'
 'itly acquired in a plug-and-play manner, leading\nto great scalibility; 2) Instead of generating from\nscratch, the paradigm generating text from some re-\ntrieved human-written reference, which potentially\nalleviates the difﬁculty of text generation.\nThis paper aims to review many representative\napproaches for retrieval-augmented text generation\ntasks including dialogue response generation (We-\nston et al., 2018), machine translation (Gu et al.,\n2018) and others (Hashimoto et al., 2018). We\n∗All authors contributed equally.\nﬁrstly present the generic paradigm of retrieval-\naugmented generation as well as three key com-\nponents under this paradigm, which are retrieval\nsources, retrieval metrics and generation models.\nThen, we introduce notable methods about\nretrieval-augmented generation, which are orga-\nnized with respect to different tasks. Speciﬁcally,\non the dialogue response generation task, exem-\nplar/template retrieval as an intermediate step has'
 'generation, and then it reviews notable ap-\nproaches according to different tasks including\ndialogue response generation, machine trans-\nlation, and other generation tasks. Finally, it\npoints out some promising directions on top of\nrecent methods to facilitate future research.\n1\nIntroduction\nRetrieval-augmented text generation, as a new\ntext generation paradigm that fuses emerging deep\nlearning technology and traditional retrieval tech-\nnology, has achieved state-of-the-art (SOTA) per-\nformance in many NLP tasks and attracted the at-\ntention of the computational linguistics community\n(Weston et al., 2018; Dinan et al., 2018; Cai et al.,\n2021). Compared with generation-based counter-\npart, this new paradigm has some remarkable ad-\nvantages: 1) The knowledge is not necessary to be\nimplicitly stored in model parameters, but is explic-\nitly acquired in a plug-and-play manner, leading\nto great scalibility; 2) Instead of generating from\nscratch, the paradigm generating text from some re-'
 'statistical machine translation (SMT) (Koehn et al.,\n2003) models (Simard and Isabelle, 2009; Koehn\nand Senellart, 2010) and in particular, we inten-\nsively highlight several popular methods to inte-\ngrating translation memory to NMT models (Gu\net al., 2018; Zhang et al., 2018; Xu et al., 2020;\nHe et al., 2021). We also review the applications\nof retrieval-augmented generation in other genera-\ntion tasks such as abstractive summarization (Peng\net al., 2019), code generation (Hashimoto et al.,\n2018), paraphrase (Kazemnejad et al., 2020; Su\net al., 2021b), and knowledge-intensive generation\n(Lewis et al., 2020b). Finally, we also point out\nsome promising directions on retrieval-augmented\ngeneration to push forward the future research.\n2\nRetrieval-Augmented Paradigm\nIn this section, we ﬁrst give a general formulation\nof retrieval-augmented text generation. Then, we\ndiscuss three major components of the retrieval-\naugmented generation paradigm, including the re-']","['Retrieval-augmented text generation has remarkable advantages over conventional generation models, including achieving state-of-the-art performance in many NLP tasks. It is particularly effective in tasks such as dialogue response generation, machine translation, and other generation tasks.']"
What are the advantages of retrieval-augmented text generation compared to generation-based models?,"The advantages of retrieval-augmented text generation compared to generation-based models are:

1) Scalability: Retrieval-augmented text generation does not require the knowledge to be implicitly stored in model parameters. Instead, it explicitly acquires knowledge in a plug-and-play manner, leading to great scalability.

2) Knowledge Acquisition: Retrieval-augmented text generation generates text from retrieved human-written references, rather than generating from scratch. This approach potentially alleviates the difficulty of text generation.

Overall, retrieval-augmented text generation combines deep learning technology with traditional retrieval technology, achieving state-of-the-art performance in many NLP tasks and offering these advantages over generation-based models.","['A Survey on Retrieval-Augmented Text Generation\nHuayang Li♥,∗\nYixuan Su♠,∗\nDeng Cai♦,∗\nYan Wang♣,∗\nLemao Liu♣,∗\n♥Nara Institute of Science and Technology\n♠University of Cambridge\n♦The Chinese University of Hong Kong\n♣Tencent AI Lab\nli.huayang.lh6@is.naist.jp, ys484@cam.ac.uk\nthisisjcykcd@gmail.com, brandenwang@tencent.com\nlemaoliu@gmail.com\nAbstract\nRecently, retrieval-augmented text generation\nattracted increasing attention of the compu-\ntational linguistics community.\nCompared\nwith conventional generation models, retrieval-\naugmented text generation has remarkable ad-\nvantages and particularly has achieved state-of-\nthe-art performance in many NLP tasks. This\npaper aims to conduct a survey about retrieval-\naugmented text generation. It ﬁrstly highlights\nthe generic paradigm of retrieval-augmented\ngeneration, and then it reviews notable ap-\nproaches according to different tasks including\ndialogue response generation, machine trans-\nlation, and other generation tasks. Finally, it'
 'generation, and then it reviews notable ap-\nproaches according to different tasks including\ndialogue response generation, machine trans-\nlation, and other generation tasks. Finally, it\npoints out some promising directions on top of\nrecent methods to facilitate future research.\n1\nIntroduction\nRetrieval-augmented text generation, as a new\ntext generation paradigm that fuses emerging deep\nlearning technology and traditional retrieval tech-\nnology, has achieved state-of-the-art (SOTA) per-\nformance in many NLP tasks and attracted the at-\ntention of the computational linguistics community\n(Weston et al., 2018; Dinan et al., 2018; Cai et al.,\n2021). Compared with generation-based counter-\npart, this new paradigm has some remarkable ad-\nvantages: 1) The knowledge is not necessary to be\nimplicitly stored in model parameters, but is explic-\nitly acquired in a plug-and-play manner, leading\nto great scalibility; 2) Instead of generating from\nscratch, the paradigm generating text from some re-'
 'dialogue response generation, machine trans-\nlation, and other generation tasks. Finally, it\npoints out some promising directions on top of\nrecent methods to facilitate future research.\n1\nIntroduction\nRetrieval-augmented text generation, as a new\ntext generation paradigm that fuses emerging deep\nlearning technology and traditional retrieval tech-\nnology, has achieved state-of-the-art (SOTA) per-\nformance in many NLP tasks and attracted the at-\ntention of the computational linguistics community\n(Weston et al., 2018; Dinan et al., 2018; Cai et al.,\n2021). Compared with generation-based counter-\npart, this new paradigm has some remarkable ad-\nvantages: 1) The knowledge is not necessary to be\nimplicitly stored in model parameters, but is explic-\nitly acquired in a plug-and-play manner, leading\nto great scalibility; 2) Instead of generating from\nscratch, the paradigm generating text from some re-\ntrieved human-written reference, which potentially'
 'more helpful in machine translation, and so on. On\nthe other hand, using a universal metric for retrieval\nmay lead to the lack of diversity of the retrieval re-\nsults. Collecting a diverse set of retrieval results\ncan improve the coverage of useful information.\nThus, considering multiple different metrics for re-\ntrieval may lead to generation with higher quality\nin the future.\n7\nConclusion\nIn this paper, we surveyed recent approaches for\nretrieval-augmented text generation. We reviewed\nand summarized the development of different com-\nponents of retrieval-augmented text generation in-\ncluding retrieval metrics, retrieval sources, and in-\ntegration paradigms. We gave in-depth discussions\nwhen retrieval-augmented text generation comes to\ndifferent applications including dialogue response\ngeneration, machine translation, and other genera-\ntion tasks. We also pointed out some future direc-\ntions for retrieval-augmented text generation.\nReferences'
 'itly acquired in a plug-and-play manner, leading\nto great scalibility; 2) Instead of generating from\nscratch, the paradigm generating text from some re-\ntrieved human-written reference, which potentially\nalleviates the difﬁculty of text generation.\nThis paper aims to review many representative\napproaches for retrieval-augmented text generation\ntasks including dialogue response generation (We-\nston et al., 2018), machine translation (Gu et al.,\n2018) and others (Hashimoto et al., 2018). We\n∗All authors contributed equally.\nﬁrstly present the generic paradigm of retrieval-\naugmented generation as well as three key com-\nponents under this paradigm, which are retrieval\nsources, retrieval metrics and generation models.\nThen, we introduce notable methods about\nretrieval-augmented generation, which are orga-\nnized with respect to different tasks. Speciﬁcally,\non the dialogue response generation task, exem-\nplar/template retrieval as an intermediate step has']","['The advantages of retrieval-augmented text generation compared to generation-based models include: 1) The knowledge is not necessary to be implicitly stored in model parameters, but is explicitly acquired in a plug-and-play manner, leading to great scalability; 2) Instead of generating from scratch, the paradigm generates text from some retrieved human-written reference, which potentially enhances the quality of the generated text.']"
What are the three key components of retrieval-augmented generation?,"The three key components of retrieval-augmented generation are:

1. Retrieval Sources: These are the sources from which relevant information is retrieved. They can include training corpora, external data, unsupervised data, and retrieval memory.

2. Retrieval Metrics: These metrics are used to measure the relevance or similarity between the retrieved information and the input sequence. They can include sparse-vector retrieval, dense-vector retrieval, and task-specific retrieval metrics.

3. Generation Models: These models generate the output sequence based on the retrieved information and the input sequence. They can include attention mechanisms, skeleton, and templates.","['In this section, we ﬁrst give a general formulation\nof retrieval-augmented text generation. Then, we\ndiscuss three major components of the retrieval-\naugmented generation paradigm, including the re-\narXiv:2202.01110v2  [cs.CL]  13 Feb 2022\nInput\nSources \n(Sec. 2.2):\nTraining \nCorpus\nExternal Data\nUnsupervised \nData\nMetrics\n(Sec. 2.3):\nSparse-vector \nRetrieval\nDense-vector \nRetrieval\nTask-specific \nRetrieval\nRetrieval Memory\nGeneration Model\nSec. 4: Machine \nTranslation\nSec. 5: Other \nTasks\nData \nAugmentation\nAttention \nMechanism\nSkeleton & \nTemplates\nInformation Retrieval\nTasks:\nSec. 3: Dialogue \nGeneration\nModels \n(Sec 2.4):\nOutput\nFigure 1: The overview of this survey.\ntrieval source, retrieval metric and integration meth-\nods.\n2.1\nFormulation\nMost text generation tasks can be formulated as a\nmapping from input sequence x to output sequence\ny : y = f(x). For instance, x and y could be the\ndialogue history and the corresponding response'
 'we will review translation memory for both statisti-\ncal machine translation (SMT) and neural machine\ntranslation (NMT).\n4.1\nTranslation Memory in SMT\nGenerally, SMT includes three key components in\na pipeline manner such as phrase table extraction,\nparameter tuning and decoding (Koehn et al., 2003;\nChiang, 2007). As a result, many efforts have been\nmade to make use of translation memory (TM) on\ntop of each component.\nConstrained Decoding with TM\nConstrained\ndecoding is the most straightforward way to in-\ntegrating TM into SMT (Smith and Clark, 2009;\nKoehn and Senellart, 2010; Zhechev and Van Gen-\nabith, 2010; Ma et al., 2011). Its basic idea is\nto reuse the useful segments in yr while trans-\nlate other segments by SMT. Speciﬁcally, the ap-\nproach consists of three steps: 1) identify the un-\nmatched segments in both xr and x through the\nedit-distance algorithm; 2) identify the unmatched\nsegments in yr, each of which is aligned to one\nunmatched segment in xr by a word alignment'
 'et al., 2019), code generation (Hashimoto et al.,\n2018), paraphrase (Kazemnejad et al., 2020; Su\net al., 2021b), and knowledge-intensive generation\n(Lewis et al., 2020b). Finally, we also point out\nsome promising directions on retrieval-augmented\ngeneration to push forward the future research.\n2\nRetrieval-Augmented Paradigm\nIn this section, we ﬁrst give a general formulation\nof retrieval-augmented text generation. Then, we\ndiscuss three major components of the retrieval-\naugmented generation paradigm, including the re-\narXiv:2202.01110v2  [cs.CL]  13 Feb 2022\nInput\nSources \n(Sec. 2.2):\nTraining \nCorpus\nExternal Data\nUnsupervised \nData\nMetrics\n(Sec. 2.3):\nSparse-vector \nRetrieval\nDense-vector \nRetrieval\nTask-specific \nRetrieval\nRetrieval Memory\nGeneration Model\nSec. 4: Machine \nTranslation\nSec. 5: Other \nTasks\nData \nAugmentation\nAttention \nMechanism\nSkeleton & \nTemplates\nInformation Retrieval\nTasks:\nSec. 3: Dialogue \nGeneration\nModels \n(Sec 2.4):\nOutput'
 'itly acquired in a plug-and-play manner, leading\nto great scalibility; 2) Instead of generating from\nscratch, the paradigm generating text from some re-\ntrieved human-written reference, which potentially\nalleviates the difﬁculty of text generation.\nThis paper aims to review many representative\napproaches for retrieval-augmented text generation\ntasks including dialogue response generation (We-\nston et al., 2018), machine translation (Gu et al.,\n2018) and others (Hashimoto et al., 2018). We\n∗All authors contributed equally.\nﬁrstly present the generic paradigm of retrieval-\naugmented generation as well as three key com-\nponents under this paradigm, which are retrieval\nsources, retrieval metrics and generation models.\nThen, we introduce notable methods about\nretrieval-augmented generation, which are orga-\nnized with respect to different tasks. Speciﬁcally,\non the dialogue response generation task, exem-\nplar/template retrieval as an intermediate step has'
 'retrieval-augmented generation, which are orga-\nnized with respect to different tasks. Speciﬁcally,\non the dialogue response generation task, exem-\nplar/template retrieval as an intermediate step has\nbeen shown beneﬁcial to informative response gen-\neration (Weston et al., 2018; Wu et al., 2019; Cai\net al., 2019a,b). In addition, there has been growing\ninterest in knowledge-grounded generation explor-\ning different forms of knowledge such as knowl-\nedge bases and external documents (Dinan et al.,\n2018; Zhou et al., 2018; Lian et al., 2019; Li et al.,\n2019; Qin et al., 2019; Wu et al., 2021; Zhang et al.,\n2021). On the machine translation task, we summa-\nrize the early work on how the retrieved sentences\n(called translation memory) are used to improve\nstatistical machine translation (SMT) (Koehn et al.,\n2003) models (Simard and Isabelle, 2009; Koehn\nand Senellart, 2010) and in particular, we inten-\nsively highlight several popular methods to inte-'
 'statistical machine translation (SMT) (Koehn et al.,\n2003) models (Simard and Isabelle, 2009; Koehn\nand Senellart, 2010) and in particular, we inten-\nsively highlight several popular methods to inte-\ngrating translation memory to NMT models (Gu\net al., 2018; Zhang et al., 2018; Xu et al., 2020;\nHe et al., 2021). We also review the applications\nof retrieval-augmented generation in other genera-\ntion tasks such as abstractive summarization (Peng\net al., 2019), code generation (Hashimoto et al.,\n2018), paraphrase (Kazemnejad et al., 2020; Su\net al., 2021b), and knowledge-intensive generation\n(Lewis et al., 2020b). Finally, we also point out\nsome promising directions on retrieval-augmented\ngeneration to push forward the future research.\n2\nRetrieval-Augmented Paradigm\nIn this section, we ﬁrst give a general formulation\nof retrieval-augmented text generation. Then, we\ndiscuss three major components of the retrieval-\naugmented generation paradigm, including the re-'
 'Active Retrieval Augmented Generation\nZhengbao Jiang1∗\nFrank F. Xu1∗\nLuyu Gao1∗\nZhiqing Sun1∗\nQian Liu2\nJane Dwivedi-Yu3\nYiming Yang1\nJamie Callan1\nGraham Neubig1\n1Language Technologies Institute, Carnegie Mellon University\n2Sea AI Lab\n3Meta AI Research\n{zhengbaj,fangzhex,luyug,zhiqings,gneubig}@cs.cmu.edu\nAbstract\nDespite the remarkable ability of large lan-\nguage models (LMs) to comprehend and gen-\nerate language, they have a tendency to hal-\nlucinate and create factually inaccurate out-\nput.\nAugmenting LMs by retrieving infor-\nmation from external knowledge resources\nis one promising solution.\nMost existing\nretrieval-augmented LMs employ a retrieve-\nand-generate setup that only retrieves informa-\ntion once based on the input.\nThis is lim-\niting, however, in more general scenarios in-\nvolving generation of long texts, where con-\ntinually gathering information throughout the\ngeneration process is essential.\nThere have\nbeen some past efforts to retrieve informa-']","['The three key components of retrieval-augmented generation are retrieval sources, retrieval metrics, and generation models.']"
What are some notable approaches to retrieval-augmented text generation in machine translation?,"The paper mentions that retrieval-augmented generation techniques have been applied in machine translation. However, it does not provide specific notable approaches for retrieval-augmented text generation in machine translation.","['generation, and then it reviews notable ap-\nproaches according to different tasks including\ndialogue response generation, machine trans-\nlation, and other generation tasks. Finally, it\npoints out some promising directions on top of\nrecent methods to facilitate future research.\n1\nIntroduction\nRetrieval-augmented text generation, as a new\ntext generation paradigm that fuses emerging deep\nlearning technology and traditional retrieval tech-\nnology, has achieved state-of-the-art (SOTA) per-\nformance in many NLP tasks and attracted the at-\ntention of the computational linguistics community\n(Weston et al., 2018; Dinan et al., 2018; Cai et al.,\n2021). Compared with generation-based counter-\npart, this new paradigm has some remarkable ad-\nvantages: 1) The knowledge is not necessary to be\nimplicitly stored in model parameters, but is explic-\nitly acquired in a plug-and-play manner, leading\nto great scalibility; 2) Instead of generating from\nscratch, the paradigm generating text from some re-'
 'in the future.\n7\nConclusion\nIn this paper, we surveyed recent approaches for\nretrieval-augmented text generation. We reviewed\nand summarized the development of different com-\nponents of retrieval-augmented text generation in-\ncluding retrieval metrics, retrieval sources, and in-\ntegration paradigms. We gave in-depth discussions\nwhen retrieval-augmented text generation comes to\ndifferent applications including dialogue response\ngeneration, machine translation, and other genera-\ntion tasks. We also pointed out some future direc-\ntions for retrieval-augmented text generation.\nReferences\nDzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-\ngio. 2014.\nNeural machine translation by jointly\nlearning to align and translate.\narXiv preprint\narXiv:1409.0473.\nAnkur Bapna and Orhan Firat. 2019. Non-parametric\nadaptation for neural machine translation. In Pro-\nceedings of the 2019 Conference of the North Amer-\nican Chapter of the Association for Computational'
 'itly acquired in a plug-and-play manner, leading\nto great scalibility; 2) Instead of generating from\nscratch, the paradigm generating text from some re-\ntrieved human-written reference, which potentially\nalleviates the difﬁculty of text generation.\nThis paper aims to review many representative\napproaches for retrieval-augmented text generation\ntasks including dialogue response generation (We-\nston et al., 2018), machine translation (Gu et al.,\n2018) and others (Hashimoto et al., 2018). We\n∗All authors contributed equally.\nﬁrstly present the generic paradigm of retrieval-\naugmented generation as well as three key com-\nponents under this paradigm, which are retrieval\nsources, retrieval metrics and generation models.\nThen, we introduce notable methods about\nretrieval-augmented generation, which are orga-\nnized with respect to different tasks. Speciﬁcally,\non the dialogue response generation task, exem-\nplar/template retrieval as an intermediate step has'
 'dialogue response generation, machine trans-\nlation, and other generation tasks. Finally, it\npoints out some promising directions on top of\nrecent methods to facilitate future research.\n1\nIntroduction\nRetrieval-augmented text generation, as a new\ntext generation paradigm that fuses emerging deep\nlearning technology and traditional retrieval tech-\nnology, has achieved state-of-the-art (SOTA) per-\nformance in many NLP tasks and attracted the at-\ntention of the computational linguistics community\n(Weston et al., 2018; Dinan et al., 2018; Cai et al.,\n2021). Compared with generation-based counter-\npart, this new paradigm has some remarkable ad-\nvantages: 1) The knowledge is not necessary to be\nimplicitly stored in model parameters, but is explic-\nitly acquired in a plug-and-play manner, leading\nto great scalibility; 2) Instead of generating from\nscratch, the paradigm generating text from some re-\ntrieved human-written reference, which potentially'
 'more helpful in machine translation, and so on. On\nthe other hand, using a universal metric for retrieval\nmay lead to the lack of diversity of the retrieval re-\nsults. Collecting a diverse set of retrieval results\ncan improve the coverage of useful information.\nThus, considering multiple different metrics for re-\ntrieval may lead to generation with higher quality\nin the future.\n7\nConclusion\nIn this paper, we surveyed recent approaches for\nretrieval-augmented text generation. We reviewed\nand summarized the development of different com-\nponents of retrieval-augmented text generation in-\ncluding retrieval metrics, retrieval sources, and in-\ntegration paradigms. We gave in-depth discussions\nwhen retrieval-augmented text generation comes to\ndifferent applications including dialogue response\ngeneration, machine translation, and other genera-\ntion tasks. We also pointed out some future direc-\ntions for retrieval-augmented text generation.\nReferences'
 'A Survey on Retrieval-Augmented Text Generation\nHuayang Li♥,∗\nYixuan Su♠,∗\nDeng Cai♦,∗\nYan Wang♣,∗\nLemao Liu♣,∗\n♥Nara Institute of Science and Technology\n♠University of Cambridge\n♦The Chinese University of Hong Kong\n♣Tencent AI Lab\nli.huayang.lh6@is.naist.jp, ys484@cam.ac.uk\nthisisjcykcd@gmail.com, brandenwang@tencent.com\nlemaoliu@gmail.com\nAbstract\nRecently, retrieval-augmented text generation\nattracted increasing attention of the compu-\ntational linguistics community.\nCompared\nwith conventional generation models, retrieval-\naugmented text generation has remarkable ad-\nvantages and particularly has achieved state-of-\nthe-art performance in many NLP tasks. This\npaper aims to conduct a survey about retrieval-\naugmented text generation. It ﬁrstly highlights\nthe generic paradigm of retrieval-augmented\ngeneration, and then it reviews notable ap-\nproaches according to different tasks including\ndialogue response generation, machine trans-\nlation, and other generation tasks. Finally, it'
 'approaches. There also exist some limitations in\nthe line of NMT. First, the information used for\nderiving reward scores is limited. The similarity\nbetween an input and retrieved examples is the\nprimary feature to derive reward scores.\nHow-\never, some information, e.g., frequencies of words\nand context, may also be beneﬁcial for integrating\nthe translation memory. Second, it remains to be\nan open question that when should we use the re-\ntrieved information and when not. In the inference\nphase, approaches tend to integrate the translation\nmemory excessively, e.g., at each time step, which\nnot only reduces the translation efﬁciency but may\nalso dampen the ﬂuency of generated results.\n5\nOther Tasks\nIn addition to dialogue system and machine trans-\nlation, retrieval-augmented generation techniques\nhave shown to be beneﬁcial in many other tasks. In\nthe following, we highlight several key tasks that\napply retrieval-augmented generation approaches.1\nLanguage Modelling\nIt has been shown that']","['Some notable approaches to retrieval-augmented text generation in machine translation include the use of retrieved sentences, also known as translation memory, to improve statistical machine translation (SMT) models as demonstrated by Koehn et al., 2003. This method was further developed by Simard and Isabelle, 2009; Koehn and Senellart, 2010. Additionally, several popular methods of integrating translation memory to Neural Machine Translation (NMT) models have been highlighted, such as those by Gu et al., 2018; Zhang et al., 2018; Xu et al., 2020; He et al., 2021. Retrieval-augmented generation has also been applied to other tasks like abstractive summarization and code generation.']"
What are the three major components of the retrieval-augmented generation paradigm?,"The three major components of the retrieval-augmented generation paradigm are:

1. Retrieval Sources: These are the sources from which relevant information is retrieved to assist in the text generation process. Examples of retrieval sources can include dialogue history, external knowledge bases, or other relevant documents.

2. Retrieval Metrics: These metrics are used to measure the relevance or similarity between the retrieved information and the desired output. Different retrieval metrics can be used depending on the specific task and the nature of the retrieval sources.

3. Generation Models: These models are responsible for generating the desired output based on the retrieved information. They take into account the input sequence and the retrieved information to generate the output sequence. The generation models can be designed using various techniques such as attention mechanisms, templates, or skeleton structures.","['In this section, we ﬁrst give a general formulation\nof retrieval-augmented text generation. Then, we\ndiscuss three major components of the retrieval-\naugmented generation paradigm, including the re-\narXiv:2202.01110v2  [cs.CL]  13 Feb 2022\nInput\nSources \n(Sec. 2.2):\nTraining \nCorpus\nExternal Data\nUnsupervised \nData\nMetrics\n(Sec. 2.3):\nSparse-vector \nRetrieval\nDense-vector \nRetrieval\nTask-specific \nRetrieval\nRetrieval Memory\nGeneration Model\nSec. 4: Machine \nTranslation\nSec. 5: Other \nTasks\nData \nAugmentation\nAttention \nMechanism\nSkeleton & \nTemplates\nInformation Retrieval\nTasks:\nSec. 3: Dialogue \nGeneration\nModels \n(Sec 2.4):\nOutput\nFigure 1: The overview of this survey.\ntrieval source, retrieval metric and integration meth-\nods.\n2.1\nFormulation\nMost text generation tasks can be formulated as a\nmapping from input sequence x to output sequence\ny : y = f(x). For instance, x and y could be the\ndialogue history and the corresponding response'
 'itly acquired in a plug-and-play manner, leading\nto great scalibility; 2) Instead of generating from\nscratch, the paradigm generating text from some re-\ntrieved human-written reference, which potentially\nalleviates the difﬁculty of text generation.\nThis paper aims to review many representative\napproaches for retrieval-augmented text generation\ntasks including dialogue response generation (We-\nston et al., 2018), machine translation (Gu et al.,\n2018) and others (Hashimoto et al., 2018). We\n∗All authors contributed equally.\nﬁrstly present the generic paradigm of retrieval-\naugmented generation as well as three key com-\nponents under this paradigm, which are retrieval\nsources, retrieval metrics and generation models.\nThen, we introduce notable methods about\nretrieval-augmented generation, which are orga-\nnized with respect to different tasks. Speciﬁcally,\non the dialogue response generation task, exem-\nplar/template retrieval as an intermediate step has'
 'et al., 2019), code generation (Hashimoto et al.,\n2018), paraphrase (Kazemnejad et al., 2020; Su\net al., 2021b), and knowledge-intensive generation\n(Lewis et al., 2020b). Finally, we also point out\nsome promising directions on retrieval-augmented\ngeneration to push forward the future research.\n2\nRetrieval-Augmented Paradigm\nIn this section, we ﬁrst give a general formulation\nof retrieval-augmented text generation. Then, we\ndiscuss three major components of the retrieval-\naugmented generation paradigm, including the re-\narXiv:2202.01110v2  [cs.CL]  13 Feb 2022\nInput\nSources \n(Sec. 2.2):\nTraining \nCorpus\nExternal Data\nUnsupervised \nData\nMetrics\n(Sec. 2.3):\nSparse-vector \nRetrieval\nDense-vector \nRetrieval\nTask-specific \nRetrieval\nRetrieval Memory\nGeneration Model\nSec. 4: Machine \nTranslation\nSec. 5: Other \nTasks\nData \nAugmentation\nAttention \nMechanism\nSkeleton & \nTemplates\nInformation Retrieval\nTasks:\nSec. 3: Dialogue \nGeneration\nModels \n(Sec 2.4):\nOutput'
 'statistical machine translation (SMT) (Koehn et al.,\n2003) models (Simard and Isabelle, 2009; Koehn\nand Senellart, 2010) and in particular, we inten-\nsively highlight several popular methods to inte-\ngrating translation memory to NMT models (Gu\net al., 2018; Zhang et al., 2018; Xu et al., 2020;\nHe et al., 2021). We also review the applications\nof retrieval-augmented generation in other genera-\ntion tasks such as abstractive summarization (Peng\net al., 2019), code generation (Hashimoto et al.,\n2018), paraphrase (Kazemnejad et al., 2020; Su\net al., 2021b), and knowledge-intensive generation\n(Lewis et al., 2020b). Finally, we also point out\nsome promising directions on retrieval-augmented\ngeneration to push forward the future research.\n2\nRetrieval-Augmented Paradigm\nIn this section, we ﬁrst give a general formulation\nof retrieval-augmented text generation. Then, we\ndiscuss three major components of the retrieval-\naugmented generation paradigm, including the re-'
 'terior distribution of retrieval given the input and\nthe target output and train it jointly with the stan-\ndard retriever and the generator by maximizing the\nevidence lower bound (ELBo) in expectation over\nretrieval.\nKnowledge-Enhanced Generation\nThe afore-\nmentioned work demonstrates that retrieval-based\ndialogue systems can be used for building bet-\nter generation-based models. In general, this is\ndone by conditioning the generation on some re-\ntrieved responses. More traditionally, to infuse\nthe response with external knowledge, the retrieval\npool is not necessarily a dialogue corpus. In fact,\nknowledge-grounded dialogue response generation\nexploring different forms of knowledge such as\nknowledge bases and external documents (Dinan\net al., 2018; Zhou et al., 2018; Lian et al., 2019;\nLi et al., 2019; Qin et al., 2019; Wu et al., 2021;\nZhang et al., 2021; Komeili et al., 2021) has been\nactively explored.\nLimitations\nWe note that there are three major'
 'retrieval-augmented generation, which are orga-\nnized with respect to different tasks. Speciﬁcally,\non the dialogue response generation task, exem-\nplar/template retrieval as an intermediate step has\nbeen shown beneﬁcial to informative response gen-\neration (Weston et al., 2018; Wu et al., 2019; Cai\net al., 2019a,b). In addition, there has been growing\ninterest in knowledge-grounded generation explor-\ning different forms of knowledge such as knowl-\nedge bases and external documents (Dinan et al.,\n2018; Zhou et al., 2018; Lian et al., 2019; Li et al.,\n2019; Qin et al., 2019; Wu et al., 2021; Zhang et al.,\n2021). On the machine translation task, we summa-\nrize the early work on how the retrieved sentences\n(called translation memory) are used to improve\nstatistical machine translation (SMT) (Koehn et al.,\n2003) models (Simard and Isabelle, 2009; Koehn\nand Senellart, 2010) and in particular, we inten-\nsively highlight several popular methods to inte-']","['The three major components of the retrieval-augmented generation paradigm are Input Sources, Metrics, and Models.']"
What is the formulation for most text generation tasks?,"Most text generation tasks can be formulated as a mapping from an input sequence (x) to an output sequence (y), where y = f(x). For example, in dialogue response generation, x and y could be the dialogue history and the corresponding response. In machine translation, x could be the text in the source language and y could be the translation in the target language.","['query formulation methods in FLARE.\ntion process. Depending on the tasks/datasets, we\nfound on average triggering retrieval for 40%-60%\nof sentences usually leads to a good performance.\nEffectiveness of different query formulation\nmethods\nLast, we study implicit query forma-\ntion by masking and explicit query formulation\nthrough question generation. In Table 4, we com-\npare the performance of FLARE with different\nmasking thresholds β. Retrieving directly with the\ncomplete sentence (β = 0) is worse than masking\ntokens with low probabilities, conﬁrming our hy-\npothesis that low-conﬁdence erroneous tokens can\ndistract retrievers. We also compare implicit and\nexplicit query formulation methods in Table 5. Per-\nformances of both methods are similar, indicating\nthat both methods can effectively reﬂect informa-\ntion needs.\n7\nConclusion\nTo aid long-form generation with retrieval aug-\nmentation, we propose an active retrieval aug-\nmented generation framework that decides when'
 'Templates\nInformation Retrieval\nTasks:\nSec. 3: Dialogue \nGeneration\nModels \n(Sec 2.4):\nOutput\nFigure 1: The overview of this survey.\ntrieval source, retrieval metric and integration meth-\nods.\n2.1\nFormulation\nMost text generation tasks can be formulated as a\nmapping from input sequence x to output sequence\ny : y = f(x). For instance, x and y could be the\ndialogue history and the corresponding response\nfor dialogue response generation, the text in the\nsource language and the translation in the target\nlanguage for machine translation, and so on.\nRecently, some researchers suggest to endow\nmodels the capability to access external memory\nvia some information retrieval techniques, so that\nthey can acquire more information in the generation\nprocess (Gu et al., 2018; Weston et al., 2018; Cai\net al., 2019b). The retrieval-augmented generation\ncan be further formulated as:\ny = f(x, z)\n(1)\nwhere z = {⟨xr, yr⟩} is a set of relevant instances\nretrieved from the original training set or external'
 'ment retrieval and memory generation.\n3.3.1\nDocument Retrieval\nGiven an input context x, the goal of the retriever\nis to select the top-k most relevant documents\nPrompt\nGenerate a list of key takeaways in complete sentences for each paragraph one by one, containing all the details such as entities,\npersons, organizations, numbers, years, and locations.\nP1: Generative Pre-trained Transformer 3 (GPT-3) is an autoregressive language model released in 2020 that uses deep\nlearning to produce human-like text. Given an initial text as prompt, it will produce text that continues the prompt.\nP2: The architecture is a decoder-only transformer network with a 2048-token-long context and then-unprecedented size of\n175 billion parameters, requiring 800GB to store. ... This eliminated the need for human supervision and for time-intensive\nhand-labeling.\nKey Takeaways: ### P1:\nOutput'
 'In this section, we ﬁrst give a general formulation\nof retrieval-augmented text generation. Then, we\ndiscuss three major components of the retrieval-\naugmented generation paradigm, including the re-\narXiv:2202.01110v2  [cs.CL]  13 Feb 2022\nInput\nSources \n(Sec. 2.2):\nTraining \nCorpus\nExternal Data\nUnsupervised \nData\nMetrics\n(Sec. 2.3):\nSparse-vector \nRetrieval\nDense-vector \nRetrieval\nTask-specific \nRetrieval\nRetrieval Memory\nGeneration Model\nSec. 4: Machine \nTranslation\nSec. 5: Other \nTasks\nData \nAugmentation\nAttention \nMechanism\nSkeleton & \nTemplates\nInformation Retrieval\nTasks:\nSec. 3: Dialogue \nGeneration\nModels \n(Sec 2.4):\nOutput\nFigure 1: The overview of this survey.\ntrieval source, retrieval metric and integration meth-\nods.\n2.1\nFormulation\nMost text generation tasks can be formulated as a\nmapping from input sequence x to output sequence\ny : y = f(x). For instance, x and y could be the\ndialogue history and the corresponding response'
 'The performance of re-\ntrieval augmented text generation is very sensitive\nto the retrieval quality, i.e., the similarity between\nthe query and the retrieved examples. Currently, re-\ntrieval augmented text generation models perform\nwell when the retrieved examples are very simi-\nlar to the query. However, they are even worse\nthan the generation models without retrieval when\nthe retrieval examples are less similar. Therefore,\nit would be important to exploit new methods to\naddress such an issue on similarity.\nRetrieval Efﬁciency\nGenerally, if one enlarges\nthe retrieval memory to some extent, it would be\npossible to retrieve an example which is very simi-\nlar to the query.Unfortunately, the downside is that\nthe overall inference for the retrieval augmented\ngeneration models is less efﬁcient due the consid-\nerable retrieval overhead. In this sense, it is urgent\nto consider some methods to trade off the retrieval\nmemory size and retrieval efﬁciency, for example,'
 'Most text generation tasks can be formulated as a\nmapping from input sequence x to output sequence\ny : y = f(x). For instance, x and y could be the\ndialogue history and the corresponding response\nfor dialogue response generation, the text in the\nsource language and the translation in the target\nlanguage for machine translation, and so on.\nRecently, some researchers suggest to endow\nmodels the capability to access external memory\nvia some information retrieval techniques, so that\nthey can acquire more information in the generation\nprocess (Gu et al., 2018; Weston et al., 2018; Cai\net al., 2019b). The retrieval-augmented generation\ncan be further formulated as:\ny = f(x, z)\n(1)\nwhere z = {⟨xr, yr⟩} is a set of relevant instances\nretrieved from the original training set or external\ndatasets. The main idea of this paradigm is that yr\nmay beneﬁt the response generation, if xr (or yr)\nis similar (or relevant) to the input x. It is worth\nnoting that xr = ∅ when unsupervised retrieval'
 'Data-to-Text Generation\nRecently, retrieval-\naugmented generation has been adapted to the task\nof data-to-text generation. To bridge the gap be-\ntween the structured data and natural language\ntext, Su et al. (2021a) propose a novel retrieval-\naugmented framework.\nSpeciﬁcally, given the\nsource data, a set of candidate texts are ﬁrst re-\ntrieved from a large unlabelled corpus. Then, a\nneural selector is applied to measure the similari-\nties between the source data and candidate texts,\nand extract a set of more ﬁne-grained prototypes\nfrom the candidates. Lastly, a generation model\ntakes the prototypes as input to produce the text\nthat describes the given structured data.\nWhile retrieval-augmented generation has been\nwidely explored in the NLP community, we sug-\ngest that future research could extend this approach\nto tasks that involve data from multiple modali-\nties. For instance, with recent advancements in\nimage-text retrieval (Jia et al., 2021; Radford et al.,'
 'erable retrieval overhead. In this sense, it is urgent\nto consider some methods to trade off the retrieval\nmemory size and retrieval efﬁciency, for example,\ndata compression for the retrieval memory.\nLocal vs. Global Optimization\nTheoretically, it\nseems promising to jointly learn retrieval metrics\nand generation models. However, in practice, there\nis an essential gap about the retrieval metric be-\ntween the training and inference phrases. In the\ntraining phase, the loss is locally back-propagated\nto only a few retrieved examples while in the infer-\nence phase the metric is globally conducted among\nall examples in the memory. It would be interesting\nto narrow such a gap when learning a better metric\nfor generation tasks.\nMulti-Modalities\nWith recent advancement in\nimage-text retrieval, directly associating images\nwith relevant text becomes possible. This urges\nresearchers to investigate the possibility of retrieval-\nbased text generation in tasks that involve data from']","['Most text generation tasks can be formulated as a mapping from input sequence x to output sequence y : y = f(x). For instance, x and y could be the dialogue history and the corresponding response for dialogue response generation, the text in the source language and the translation in the target language for machine translation, and so on. Recently, some researchers suggest to endow models the capability to access external memory via some information retrieval techniques, so that they can acquire more information in the generation process. The retrieval-augmented generation can be further formulated as: y = f(x, z) where z = {⟨xr, yr⟩} is a set of relevant instances retrieved from the original training set or external.']"
What are the three kinds of sources from which retrieval memory can be retrieved?,"The three kinds of sources from which retrieval memory can be retrieved are:

1. Training corpus: Most previous studies search the external memory from its training corpus. This means that the retrieval memory is retrieved from the same dataset that was used to train the model.

2. External datasets: Retrieval memory can also be retrieved from external datasets that are in the same format as the training corpus. These external datasets provide additional information that may not be present in the training corpus.

3. Large-scale unsupervised corpus: Another source of retrieval memory is large-scale unsupervised corpus. This refers to a collection of text data that has not been labeled or annotated.","['may beneﬁt the response generation, if xr (or yr)\nis similar (or relevant) to the input x. It is worth\nnoting that xr = ∅ when unsupervised retrieval\nsources are used. In general, the retrieval mem-\nory can be retrieved from three kinds of sources:\nthe training corpus, external datasets in the same\nformat with the training corpus, and large-scale\nunsupervised corpus (§2.2). Metrics that evaluate\nthe relevance between text are varied as well, in\n§2.3 we divided them into three categories: sparse-\nvector retrieval, dense-vector retrieval, and training-\nbased retrieval. Finally, how to integrate the re-\ntrieval memory to the generation model is also sig-\nniﬁcant, we also introduce some popular integra-\ntion approaches in §2.4.\n2.2\nRetrieval Sources\nTraining Corpus\nMost previous studies search\nthe external memory from its training corpus (Song\net al., 2016; Gu et al., 2018; Weston et al., 2018).\nIn the inference time, retrieved examples with high'
 'retrieved from the original training set or external\ndatasets. The main idea of this paradigm is that yr\nmay beneﬁt the response generation, if xr (or yr)\nis similar (or relevant) to the input x. It is worth\nnoting that xr = ∅ when unsupervised retrieval\nsources are used. In general, the retrieval mem-\nory can be retrieved from three kinds of sources:\nthe training corpus, external datasets in the same\nformat with the training corpus, and large-scale\nunsupervised corpus (§2.2). Metrics that evaluate\nthe relevance between text are varied as well, in\n§2.3 we divided them into three categories: sparse-\nvector retrieval, dense-vector retrieval, and training-\nbased retrieval. Finally, how to integrate the re-\ntrieval memory to the generation model is also sig-\nniﬁcant, we also introduce some popular integra-\ntion approaches in §2.4.\n2.2\nRetrieval Sources\nTraining Corpus\nMost previous studies search\nthe external memory from its training corpus (Song'
 'To be speciﬁc, when translating an input sentence\nx, they ﬁrstly retrieve many similar bilingual sen-\ntences {⟨xr, yr⟩}, and then tune the parameters on\ntop of the retrieved sentences as well as a given de-\nvelopment dataset in a sentence-wise manner, i.e.,\nit performs an independent tuning for each input\nsentence. To improve the efﬁciency of each tuning\nstep, it propose a local update on top of {⟨xr, yr⟩}\nfrom a baseline model.\nDespite the successes of translation memory in\nSMT, there are still some limitations for the above\nthree kinds of methods. Firstly, all these methods\nemploy fuzzy score for retrieval which is highly de-\npendent on word matching and thus can not recall\nsuch examples which are similar in word seman-\ntics but different in surface form. Secondly, these\nmethods integrate the retrieved examples into a\nmodule of SMT in the ways which can not make\nfull use of the knowledge in retrieved examples.\nFor example, the integration ways in the ﬁrst two'
 'In this section, we ﬁrst give a general formulation\nof retrieval-augmented text generation. Then, we\ndiscuss three major components of the retrieval-\naugmented generation paradigm, including the re-\narXiv:2202.01110v2  [cs.CL]  13 Feb 2022\nInput\nSources \n(Sec. 2.2):\nTraining \nCorpus\nExternal Data\nUnsupervised \nData\nMetrics\n(Sec. 2.3):\nSparse-vector \nRetrieval\nDense-vector \nRetrieval\nTask-specific \nRetrieval\nRetrieval Memory\nGeneration Model\nSec. 4: Machine \nTranslation\nSec. 5: Other \nTasks\nData \nAugmentation\nAttention \nMechanism\nSkeleton & \nTemplates\nInformation Retrieval\nTasks:\nSec. 3: Dialogue \nGeneration\nModels \n(Sec 2.4):\nOutput\nFigure 1: The overview of this survey.\ntrieval source, retrieval metric and integration meth-\nods.\n2.1\nFormulation\nMost text generation tasks can be formulated as a\nmapping from input sequence x to output sequence\ny : y = f(x). For instance, x and y could be the\ndialogue history and the corresponding response'
 'methods integrate the retrieved examples into a\nmodule of SMT in the ways which can not make\nfull use of the knowledge in retrieved examples.\nFor example, the integration ways in the ﬁrst two\nkinds (constrained decoding and phrase table ag-\ngregation) are heuristic and not optimized towards\ntranslation quality; the parameter tuning method\nﬁne-tunes few parameters for log-linear based SMT\nwhich are not enough to preserve sufﬁcient knowl-\nedge from retrieved examples. Thirdly, since SMT\nperforms in a pipeline manner, it is intractable to\njointly optimize retrieval metrics as well as SMT\nmodels. Consequently, all these methods adopt an\noff-the-shelf metric for retrieval, leading to sub-\noptimal performance.\n4.2\nTranslation Memory in NMT\nTranslation memory has been widely explored in\nNeural Machine Translation (NMT). Depending\non when retrieval is involved, we can categorize\nprevious works into two classes: 1) an NMT model\nleans how to cooperate with the retrieval model in'
 'Most previous studies search\nthe external memory from its training corpus (Song\net al., 2016; Gu et al., 2018; Weston et al., 2018).\nIn the inference time, retrieved examples with high\nrelevant scores could be regarded as extra refer-\nences and reduce model’s uncertainty in generation.\nThe main motivation of those works is to to store\nknowledge not only in the model parameters but\nalso in an explicit and accessible form, making the\nmodel be able to re-access it during inference.\nExternal Data\nSome researchers also propose to\nretrieval relevant samples from external datasets\n(Su et al., 2021c; Xiao et al., 2021). In these stud-\nies, the retrieval pool is different with the training\ncorpus, which can further provide additional infor-\nmation that are not contained in the training corpus.\nThis is especially beneﬁcial for applications such\nas domain adaptation and knowledge update. For\nexample, Khandelwal et al. (2020a); Zheng et al.\n(2021a) employ the in-domain dataset as the exter-'
 'Answer: In order to ﬁgure out its interpretations, we need to consider different criteria to determine a city’s size. City size can\nbe measured by two criteria: population or area. Therefore, this question has 2 interpretations: (1) What is the second largest\ncity in the USA by population? (2) What is the second largest city in the USA by area? The answers to all interpretations are:\n(1) The second largest city in the USA by population is Los Angeles, California. (2) The second largest city in the USA by\narea is Juneau, Alaska.\nGiven an ambiguous question and a hint on which aspect of the question is ambiguous, ﬁgure out its interpreta-\ntions and answer them one by one.\nQuestion: When was bohemian rhapsody released as a single?\nHint: This question is ambiguous in terms of which country’s release of the single is being referred to.\nAnswer: In order to ﬁgure out its interpretations, we need to consider different countries where Bohemian Rhapsody is']","['The three kinds of sources from which retrieval memory can be retrieved are the training corpus, external datasets in the same format with the training corpus, and large-scale unsupervised corpus.']"
What is the main motivation behind storing knowledge in an explicit and accessible form during inference?,"The main motivation behind storing knowledge in an explicit and accessible form during inference is to allow the model to re-access that knowledge when generating outputs. By storing knowledge not only in the model parameters but also in an external memory, the model can retrieve relevant information from this memory and reduce uncertainty in generation. This is particularly beneficial for tasks such as domain adaptation and knowledge update, where the retrieval pool contains additional information that is not present in the training corpus. Storing knowledge in an explicit and accessible form enables the model to make more informed and accurate decisions during the generation process.","['ter align with knowledge-intensive tasks (Petroni et al.,\n2020), such as retrieval and OpenQA (Chen et al., 2017).\nLearning to retrieve useful documents to augment the\nlanguage model is a challenging task, since human anno-\ntations on the usefulness of augmentation documents are\ncostly and seldom available. The most straightforward\nway is to use representations from raw pretrained lan-\nguage models to ﬁnd documents similar to the task input,\ni.e., as unsupervised dense retrieval (Guu et al., 2020;\nBorgeaud et al., 2022). Adapting dense retrieval mod-\nels trained for relevance matching is another common\nchoice (Izacard and Grave, 2020b; Lewis et al., 2020;\nYu et al., 2021). A more formal solution is to jointly\nlearn the augmentation components end-to-end using\nsupervision from the ﬁnal task, for example, treating the\naugmentation as latent variables and applying EM (Zhao\net al., 2021), or distilling the augmentation component\nfrom feedback of the ﬁnal model (Izacard and Grave,'
 'Most previous studies search\nthe external memory from its training corpus (Song\net al., 2016; Gu et al., 2018; Weston et al., 2018).\nIn the inference time, retrieved examples with high\nrelevant scores could be regarded as extra refer-\nences and reduce model’s uncertainty in generation.\nThe main motivation of those works is to to store\nknowledge not only in the model parameters but\nalso in an explicit and accessible form, making the\nmodel be able to re-access it during inference.\nExternal Data\nSome researchers also propose to\nretrieval relevant samples from external datasets\n(Su et al., 2021c; Xiao et al., 2021). In these stud-\nies, the retrieval pool is different with the training\ncorpus, which can further provide additional infor-\nmation that are not contained in the training corpus.\nThis is especially beneﬁcial for applications such\nas domain adaptation and knowledge update. For\nexample, Khandelwal et al. (2020a); Zheng et al.\n(2021a) employ the in-domain dataset as the exter-'
 'erable retrieval overhead. In this sense, it is urgent\nto consider some methods to trade off the retrieval\nmemory size and retrieval efﬁciency, for example,\ndata compression for the retrieval memory.\nLocal vs. Global Optimization\nTheoretically, it\nseems promising to jointly learn retrieval metrics\nand generation models. However, in practice, there\nis an essential gap about the retrieval metric be-\ntween the training and inference phrases. In the\ntraining phase, the loss is locally back-propagated\nto only a few retrieved examples while in the infer-\nence phase the metric is globally conducted among\nall examples in the memory. It would be interesting\nto narrow such a gap when learning a better metric\nfor generation tasks.\nMulti-Modalities\nWith recent advancement in\nimage-text retrieval, directly associating images\nwith relevant text becomes possible. This urges\nresearchers to investigate the possibility of retrieval-\nbased text generation in tasks that involve data from'
 'this erroneous sentence as a query could prompt the\nretriever to retrieve irrelevant information, which\ncould potentially mislead future generations. We\npropose two simple methods to overcome this issue\nas illustrated in Figure 3.\nMasked sentences as implicit queries.\nThe ﬁrst\nmethod masks out low-conﬁdence tokens in ˆst with\nprobabilities below a threshold β ∈ [0, 1], where a\nhigher β results in more aggressive masking. This\nremoves potential distractions from the sentence to\nimprove retrieval accuracy.\nJoe Biden attended the University of Pennsylvania, \nwhere he earned a law degree.\nAsk a question to which the answer is “the University of Pennsylvania”\nAsk a question to which the answer is “a law degree”\nWhat university did Joe Biden attend?\nWhat degree did Joe Biden earn?\nimplicit query \nby masking\nexplicit query by\n question generation\nJoe Biden attended  , where he earned  .\nLM such as ChatGPT\nFigure 3: Implicit the explicit query formulation. To-'
 'music was popular. Roy Orbison is popular in both the US Hot 100 and Canada, and the UK and Ireland. Therefore, this\nquestion has 2 interpretations: (1) What was Roy Orbison’s ﬁrst number one hit in the US Hot 100 and Canada? (2) What\nwas Roy Orbison’s ﬁrst number one hit in the UK and Ireland? The answers to all interpretations are: (1) Running Scared\nwas the ﬁrst number one hit for Roy Orbison in the US Hot 100 and Canada. (2) Only the Lonely (Know the Way I Feel) was\nthe ﬁrst number one hit for Roy Orbison in the UK and Ireland.\nGiven an ambiguous question and a hint on which aspect of the question is ambiguous, ﬁgure out its interpreta-\ntions and answer them one by one.\nQuestion: What is the criminal’s name in the breakfast club?\nHint: This question is ambiguous in terms of which speciﬁc name is being referred to - the character’s name or the actor’s\nname.\nAnswer: In order to ﬁgure out its interpretations, we need to consider both possibilities: the character’s name or the actor’s'
 'Izacard et al., 2022; Jiang et al., 2022; Shi et al.,\n2023). These single-time retrieval-augmented LMs\nhave been found to outperform purely paramet-\nric LMs, particularly for short-form knowledge-\nintensive generation tasks such as factoid QA\n(Kwiatkowski et al., 2019; Joshi et al., 2017) and\nfact checking (Thorne et al., 2018), where the in-\nformation needs are clear in the user’s input, and\nit is sufﬁcient to retrieve relevant knowledge once\nsolely based on the input.\nIn recent years, increasingly powerful large LMs\nhave demonstrated abilities in more complex tasks\nthat involve generating long-form output, such as\nlong-form QA (Fan et al., 2019; Stelmakh et al.,\n2022), open-domain summarization (Cohen et al.,\n2021; Hayashi et al., 2021; Giorgi et al., 2022),\nand (chain-of-thought; CoT) reasoning (Wei et al.,\n2022; Ho et al., 2020; Geva et al., 2021; Hendrycks\net al., 2020). In contrast to short-form generation,\narXiv:2305.06983v1  [cs.CL]  11 May 2023'
 'in the US Hot 100 and Canada. (2) Only the Lonely (Know the Way I Feel) was the ﬁrst number one hit for Roy Orbison in\nthe UK and Ireland.\nGiven an ambiguous question, ﬁgure out its interpretations and answer them one by one.\nQuestion: What is the criminal’s name in the breakfast club?\nAnswer: This question is ambiguous in terms of which speciﬁc name is being referred to - the character’s name or the actor’s\nname. In order to ﬁgure out its interpretations, we need to consider both possibilities: the character’s name or the actor’s\nname. Therefore, this question has 2 interpretations: (1) What is the criminal’s character name in The Breakfast Club? (2)\nWhat is the the name of the actor who played the criminal in The Breakfast Club? The answers to all interpretations are: (1)\nJohn Bender was the name of the criminal’s character in The Breakfast Club. (2) Judd Nelson was the actor of the criminal in\nThe Breakfast Club.'
 'throughout the generation process, and are appli-\ncable to a variety of long-form generation tasks?\nWe consider a new paradigm, active retrieval aug-\nmented generation. Our hypothesis regarding when\nto retrieve is that LMs should retrieve information\nonly when they lack the required knowledge to\navoid unnecessary or inappropriate retrieval that\noccurs in passive retrieval-augmented LMs (Khan-\ndelwal et al., 2020; Borgeaud et al., 2022; Ram\net al., 2023; Trivedi et al., 2022). Given the obser-\nvation that large LMs tend to be well-calibrated and\nlow probability/conﬁdence often indicates a lack\nof knowledge (Jiang et al., 2021; Kadavath et al.,\n2022), we adopt an active retrieval strategy that\nonly retrieves when LMs generate low-probability\ntokens. When deciding what to retrieve, we argue\nthat it is important to consider what LMs intend to\ngenerate in the future, as the goal of active retrieval\nis to beneﬁt future generations. Therefore, we pro-']","[""The main motivation behind storing knowledge in an explicit and accessible form during inference is to not only store knowledge in the model parameters but also make the model be able to re-access it during inference. This can reduce the model's uncertainty in generation by providing extra references with high relevant scores retrieved from the training corpus.""]"
What is the main idea behind the cross-lingual retriever proposed by Cai et al. (2021) for machine translation?,"The main idea behind the cross-lingual retriever proposed by Cai et al. (2021) is to align source-side sentences and their corresponding target-side translations in a dense vector space. This alignment allows the retriever to directly connect the source-side input with the target-side translations, enabling the use of monolingual data in the target language as memories. In other words, the retriever retrieves the most similar target sentence in a monolingual dataset using a source sentence as a query.","['This is especially beneﬁcial for applications such\nas domain adaptation and knowledge update. For\nexample, Khandelwal et al. (2020a); Zheng et al.\n(2021a) employ the in-domain dataset as the exter-\nnal memory to achieve fast domain adaptation for\nmachine translation.\nUnsupervised Data\nOne limitation for previous\ntwo sources is that the datasets have to be super-\nvised datasets consisting of aligned input-output\npairs. For machine translation, Cai et al. (2021) pro-\npose a cross-lingual retriever to directly retrieve tar-\nget sentence from unsupervised corpus (i.e., mono-\nlingual corpus in the target language). The main\nidea is aligning source-side sentences and the corre-\nsponding target-side translations in a dense vector\nspace, i.e., aligning x and yr when xr is absent.\nAs a result, the retriever directly connects the dots\nbetween the source-side input and target-side trans-\nlations, enabling monolingual data in the target\nlanguage to be used alone as memories.\n2.3\nRetrieval Metrics'
 'ferent from previous works that rely on bilingual\nmemories, Cai et al. (2021) propose a framework\nthat can retrieve the most similar target sentence in\na monolingual dataset, using a source sentence as\nquery.\nLimitations\nIn the section of SMT, we have\nshowed some limitations of the retrieval augmented\napproaches. There also exist some limitations in\nthe line of NMT. First, the information used for\nderiving reward scores is limited. The similarity\nbetween an input and retrieved examples is the\nprimary feature to derive reward scores.\nHow-\never, some information, e.g., frequencies of words\nand context, may also be beneﬁcial for integrating\nthe translation memory. Second, it remains to be\nan open question that when should we use the re-\ntrieved information and when not. In the inference\nphase, approaches tend to integrate the translation\nmemory excessively, e.g., at each time step, which\nnot only reduces the translation efﬁciency but may\nalso dampen the ﬂuency of generated results.\n5'
 'boost the quality of ﬁnal generation. To this end,\nCai et al. (2021) propose to unify the memory\nretriever and its downstream generation model\ninto a learnable whole. Such memory retrieval is\nend-to-end optimized for task-speciﬁc objectives.\n2.4\nIntegration\nData Augmentation\nThere are several ways to\nintegrate the retrieved external memory in gener-\nation. One straightforward way is data augmen-\ntation, which constructs some augmented inputs\nby concatenating spans from {⟨xr, yr⟩} with the\noriginal input x. By training on the augmented\ninputs, a generation model implicitly leans how\nto integrate the retrieved information. Despite the\nsimplicity, this kind of methods works efﬁciently\nin lots of tasks (Song et al., 2016; Weston et al.,\n2018; Bulte and Tezcan, 2019).\nAttention\nMechanisms\nAnother\nintegration\nmethod\nis\nbased\non\nattention\nmechanisms\n(Bahdanau et al., 2014). The main idea of this\nfashion is adopting additional encoders (in various'
 'ral Language Processing and the 9th International\nJoint Conference on Natural Language Processing\n(EMNLP-IJCNLP), pages 1866–1875.\nDeng Cai, Yan Wang, Huayang Li, Wai Lam, and\nLemao Liu. 2021. Neural machine translation with\nmonolingual translation memory. In Proceedings of\nthe 59th Annual Meeting of the Association for Com-\nputational Linguistics and the 11th International\nJoint Conference on Natural Language Processing\n(Volume 1: Long Papers), pages 7307–7318, Online.\nAssociation for Computational Linguistics.\nQian Cao, Shaohui Kuang, and Deyi Xiong. 2019.\nLearning to reuse translations: Guiding neural ma-\nchine translation with examples.\narXiv preprint\narXiv:1911.10732.\nQian Cao and Deyi Xiong. 2018.\nEncoding gated\ntranslation memory into neural machine translation.\nIn Proceedings of the 2018 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n3042–3047.\nZiqiang Cao, Wenjie Li, Sujian Li, and Furu Wei.\n2018. Retrieve, rerank and rewrite: Soft template'
 'model. This happens with improper training in-\nstances. Due to the one-to-many nature, it hap-\npens frequently that a retrieved response (extracted\nskeleton) is suitable for responding to the query,\nbut inconsistent with the current target response.\nEarlier studies (Weston et al., 2018; Wu et al.,\n2019; Cai et al., 2019a) alleviate the above prob-\nlems by putting hard constraints on the data (e.g.,\ndiscarding data with low similarity of the retrieved\nresponse and the target response), which, however,\ngreatly reduces the amount of usable data. Cai\net al. (2019b) employ a random mechanism for\ngenerating the skeletons used for training, which\nextract skeletons from the corresponding responses\nwith some deliberate disturbance. Paranjape et al.\n(2021) propose to model the retriever after the pos-\nterior distribution of retrieval given the input and\nthe target output and train it jointly with the stan-\ndard retriever and the generator by maximizing the'
 'monolingual translation memory. In Proceedings of\nthe 59th Annual Meeting of the Association for Com-\nputational Linguistics and the 11th International\nJoint Conference on Natural Language Processing\n(Volume 1: Long Papers), pages 7307–7318, Online.\nAssociation for Computational Linguistics.\nQian Cao, Shaohui Kuang, and Deyi Xiong. 2019.\nLearning to reuse translations: Guiding neural ma-\nchine translation with examples.\narXiv preprint\narXiv:1911.10732.\nQian Cao and Deyi Xiong. 2018.\nEncoding gated\ntranslation memory into neural machine translation.\nIn Proceedings of the 2018 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n3042–3047.\nZiqiang Cao, Wenjie Li, Sujian Li, and Furu Wei.\n2018. Retrieve, rerank and rewrite: Soft template\nbased neural summarization. In Proceedings of the\n56th Annual Meeting of the Association for Com-\nputational Linguistics, ACL 2018, Melbourne, Aus-\ntralia, July 15-20, 2018, Volume 1: Long Papers,'
 'Liu Yang, Junjie Hu, Minghui Qiu, Chen Qu, Jian-\nfeng Gao, W Bruce Croft, Xiaodong Liu, Yelong\nShen, and Jingjing Liu. 2019.\nA hybrid retrieval-\ngeneration neural conversation model. In Proceed-\nings of the 28th ACM international conference on in-\nformation and knowledge management, pages 1341–\n1350.\nJingyi Zhang, Masao Utiyama, Eiichiro Sumita, Gra-\nham Neubig, and Satoshi Nakamura. 2018. Guiding\nneural machine translation with retrieved translation\npieces. In Proceedings of the 2018 Conference of the\nNorth American Chapter of the Association for Com-\nputational Linguistics: Human Language Technolo-\ngies, Volume 1 (Long Papers), pages 1325–1335.\nYizhe Zhang, Siqi Sun, Xiang Gao, Yuwei Fang, Chris\nBrockett, Michel Galley, Jianfeng Gao, and Bill\nDolan. 2021.\nJoint retrieval and generation train-\ning for grounded text generation.\narXiv preprint\narXiv:2105.06597.\nZhuosheng Zhang, Kehai Chen, Rui Wang, Masao\nUtiyama, Eiichiro Sumita, Zuchao Li, and Hai Zhao.\n2020.'
 'Most text generation tasks can be formulated as a\nmapping from input sequence x to output sequence\ny : y = f(x). For instance, x and y could be the\ndialogue history and the corresponding response\nfor dialogue response generation, the text in the\nsource language and the translation in the target\nlanguage for machine translation, and so on.\nRecently, some researchers suggest to endow\nmodels the capability to access external memory\nvia some information retrieval techniques, so that\nthey can acquire more information in the generation\nprocess (Gu et al., 2018; Weston et al., 2018; Cai\net al., 2019b). The retrieval-augmented generation\ncan be further formulated as:\ny = f(x, z)\n(1)\nwhere z = {⟨xr, yr⟩} is a set of relevant instances\nretrieved from the original training set or external\ndatasets. The main idea of this paradigm is that yr\nmay beneﬁt the response generation, if xr (or yr)\nis similar (or relevant) to the input x. It is worth\nnoting that xr = ∅ when unsupervised retrieval']","['The main idea behind the cross-lingual retriever proposed by Cai et al. (2021) for machine translation is to directly retrieve the target sentence from an unsupervised corpus, which is a monolingual corpus in the target language. This is achieved by aligning source-side sentences and the corresponding target-side translations in a dense vector space, even when the source-side reference is absent. This method allows the retriever to directly connect the source-side input and target-side translations, enabling the use of monolingual data in the target language alone as memories.']"
What are some widely used sparse-vector retrieval methods?,Some widely used sparse-vector retrieval methods include TF-IDF (Term Frequency-Inverse Document Frequency) and BM25 (Best Matching 25). These methods are commonly used to measure the similarity between an input sequence and a retrieval corpus by matching keywords efficiently with an inverted index.,"['between the source-side input and target-side trans-\nlations, enabling monolingual data in the target\nlanguage to be used alone as memories.\n2.3\nRetrieval Metrics\nSparse-vector Retrieval\nGiven an input se-\nquence x and a retrieval corpus, retrieval model\naims to retrieve a set of relevant examples z =\n{⟨xr, yr⟩} from the corpus. When a supervised\ncorpus is used, {⟨xr, yr⟩} is retrieved by measur-\ning the similarity between x and xr. For simi-\nlarity measurement, sparse-vector retrieval meth-\nods such as TF-IDF and BM25 (Robertson and\nZaragoza, 2009) are widely used. They match key-\nwords efﬁciently with an inverted index.\nDense-vector Retrieval\nHowever, these meth-\nods prefer examples with similar surfaces, and may\nfail to retrieve examples that are only semantically\nrelevant. To alleviate above problem, some stud-\nies (Cao and Xiong, 2018) attempt to retrieve in\ndense-vector space instead of the lexical overlap.\nRecent work (Lee et al., 2019) makes use of pre-'
 '2.3\nRetrieval Metrics\nSparse-vector Retrieval\nGiven an input se-\nquence x and a retrieval corpus, retrieval model\naims to retrieve a set of relevant examples z =\n{⟨xr, yr⟩} from the corpus. When a supervised\ncorpus is used, {⟨xr, yr⟩} is retrieved by measur-\ning the similarity between x and xr. For simi-\nlarity measurement, sparse-vector retrieval meth-\nods such as TF-IDF and BM25 (Robertson and\nZaragoza, 2009) are widely used. They match key-\nwords efﬁciently with an inverted index.\nDense-vector Retrieval\nHowever, these meth-\nods prefer examples with similar surfaces, and may\nfail to retrieve examples that are only semantically\nrelevant. To alleviate above problem, some stud-\nies (Cao and Xiong, 2018) attempt to retrieve in\ndense-vector space instead of the lexical overlap.\nRecent work (Lee et al., 2019) makes use of pre-\ntrained language models, which encodes the text to\nlow-dimensional dense vectors via BERT-based en-\ncoders. The retrieval score are computed via inner'
 'Retrievers. We adopt two widely used retriev-\ners to initialize AAR: ANCE initialized from\nT5Base (Raffel et al., 2020; Ge et al., 2023) and\nContriever (Izacard et al., 2021) initialized from\nBERTBase (Devlin et al., 2019). Both of them have\nbeen fine-tuned on MS MARCO (Bajaj et al., 2016)\npreviously. For the retrieval corpus, we choose the\nMS MARCO (Bajaj et al., 2016) for MMLU and\nthe KILT-Wikipedia (Petroni et al.) for PopQA.\nLanguage Models. We adopt Flan-T5 (Chung\net al., 2022) series as our backbone for encoder-\ndecoder LMs and InstructGPT1 (Ouyang et al.,\n2022) as our backbone for decoder-only LMs.\nThese models have been multi-task instruction-\nfinetuned and are widely utilized for assessing zero-\nshot generalization (Zhou et al., 2023).\nImplementation Details.\nWe utilize the MS\nMARCO (Bajaj et al., 2016) as our source task\nTs since it is the common choice to train the re-\ntriever (Xin et al., 2022). This dataset consists\nof high-quality questions that require real-world'
 'setup. More details can be found in Appendix A.\n4.1\nTarget Tasks\nFollowing prior works (Chung et al., 2022; Mallen\net al., 2022), we choose MMLU (Hendrycks et al.,\n2021) and PopQA (Mallen et al., 2022) as target\ntasks Tt.\nMMLU is a multitask language understanding\ndataset, which includes 57 multi-choice question\nanswering subtasks. These subtasks can be gen-\nerally classified into four categories: humanities,\nsocial sciences, STEM, and other. We average the\naccuracy of the subtasks in each category to ob-\ntain the final score. We report the accuracy of the\nevaluation set in our main experiments.\nPopQA is an entity-centric question answering\ndataset that mainly concentrates on long-tail ques-\ntions. We report the accuracy of the test set in our\nmain experiments.\n4.2\nOur Method\nRetrievers. We adopt two widely used retriev-\ners to initialize AAR: ANCE initialized from\nT5Base (Raffel et al., 2020; Ge et al., 2023) and\nContriever (Izacard et al., 2021) initialized from'
 'relevant. To alleviate above problem, some stud-\nies (Cao and Xiong, 2018) attempt to retrieve in\ndense-vector space instead of the lexical overlap.\nRecent work (Lee et al., 2019) makes use of pre-\ntrained language models, which encodes the text to\nlow-dimensional dense vectors via BERT-based en-\ncoders. The retrieval score are computed via inner\nproducts between vectors.\nTask-speciﬁc\nRetrieval\nSimilarity-based\nre-\ntrieval is based on a simple heuristic. That is, the\nmore xr resembles with x, the more likely xr\nand yr will help the generation. However, the\nmost similar one by universal textual similarity\ndoes not necessarily serve the best for downstream\nmodels.\nIdeally, the retrieval metric would be\nlearned from the data in a task-dependent way: we\nwish to consider a memory only if it can indeed\nboost the quality of ﬁnal generation. To this end,\nCai et al. (2021) propose to unify the memory\nretriever and its downstream generation model\ninto a learnable whole. Such memory retrieval is'
 'SciFact\n\x13\nBinary\n920\n—-\n300\n5,183\n1.1\n12.37\n213.63\nTable 8: Statistics of the augmenting corpora.\nDatasets\nCorpus Size\nAvg. Doc Length\nMS MARCO\n502,939\n56.0\nMeSH\n32,326\n16.8\nWiki\n21,015,324\n100.0\nfor each passage as additional training data for the target\ndomain to continue to ﬁne-tune the TAS-B (Hofstätter\net al., 2021) model.\nLexical Retrieval\nLexical retrieval is a score func-\ntion for token matching calculated between two\nhigh-dimensional sparse vectors with token weights.\nBM25 (Robertson et al., 2009) is the most commonly\nused lexical retrieval function. We use the BM25 results\nreported in Thakur et al. (2021b) for comparison.\nLate Interaction\nWe also consider a late interac-\ntion baseline, namely ColBERT (Khattab and Zaharia,\n2020b). The model computes multiple contextualized\nembeddings for each token of queries and documents,\nand then uses a maximum similarity function to retrieve\nrelevant documents. This type of matching requires sig-'
 'ferent from previous works that rely on bilingual\nmemories, Cai et al. (2021) propose a framework\nthat can retrieve the most similar target sentence in\na monolingual dataset, using a source sentence as\nquery.\nLimitations\nIn the section of SMT, we have\nshowed some limitations of the retrieval augmented\napproaches. There also exist some limitations in\nthe line of NMT. First, the information used for\nderiving reward scores is limited. The similarity\nbetween an input and retrieved examples is the\nprimary feature to derive reward scores.\nHow-\never, some information, e.g., frequencies of words\nand context, may also be beneﬁcial for integrating\nthe translation memory. Second, it remains to be\nan open question that when should we use the re-\ntrieved information and when not. In the inference\nphase, approaches tend to integrate the translation\nmemory excessively, e.g., at each time step, which\nnot only reduces the translation efﬁciency but may\nalso dampen the ﬂuency of generated results.\n5']",['TF-IDF and BM25 are some widely used sparse-vector retrieval methods.']
